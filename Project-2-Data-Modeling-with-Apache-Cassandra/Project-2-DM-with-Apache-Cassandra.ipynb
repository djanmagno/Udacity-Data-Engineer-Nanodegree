{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import Python packages "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# checking your current working directory\n",
    "print('The current working directory is: \\n {}\\n'.format(os.getcwd()))\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print('The file path list has {} paths inside.'.format(len(file_path_list)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The current working directory is: \n",
      " /Users/djanmagno/Documents/Data_Science/Udacity-Data-Engineering-Nanodegree/Project-2-Data-Modeling-with-Apache-Cassandra\n",
      "\n",
      "The file path list has 30 paths inside.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print('Total number of rows: {}\\n'.format(len(full_data_rows_list)))\n",
    "\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "try:\n",
    "    with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "        writer = csv.writer(f, dialect='myDialect')\n",
    "        writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                    'level','location','sessionId','song','userId'])\n",
    "        for row in full_data_rows_list:\n",
    "            if (row[0] == ''):\n",
    "                continue\n",
    "            writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "\n",
    "    print('CSV file created with success.')\n",
    "except Exception as e:\n",
    "    # Printing error\n",
    "    print('The error was: {}'.format(e))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of rows: 8056\n",
      "\n",
      "CSV file created with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print('The number of rows in the CSV file is: {}'.format(sum(1 for line in f)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of rows in the CSV file is: 6821\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II. Apache Cassandra coding portion of the project. \n",
    "\n",
    "## Now we are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apache Cassandra code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating a Cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    # Making a connection to a Cassandra instance my local machine\n",
    "    cluster = Cluster([('127.0.0.1')])\n",
    "\n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    session = cluster.connect()\n",
    "    print('Connection with Cassandra established with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connection with Cassandra established with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Keyspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Creating the Keyspace \n",
    "query = \"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS sparkify_ks\n",
    "WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor' : 1}\n",
    "\"\"\"\n",
    "try:\n",
    "    # Creating keyspace sparkify_ks\n",
    "    session.execute(query)\n",
    "    print('KEYSPACE sparkify_ks created with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KEYSPACE sparkify_ks created with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set Keyspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Setting KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    # Setting KEYSPACE to sparkify_ks\n",
    "    session.set_keyspace('sparkify_ks')\n",
    "    print('KEYSPACE set to sparkify_ks with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KEYSPACE set to sparkify_ks with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "```\n",
    "    SELECT artist, song, lenght FROM event_history WHERE sessionId = 338 AND itemInSession  = 4\n",
    "```\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "```\n",
    "    SELECT artist, song, firstName, lastName FROM event_history WHERE userid = 10 AND sessionid = 182       \n",
    "```\n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "```\n",
    "    SELECT firstName, LastName FROM event_history WHERE song = 'All Hands Against His Own'\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Modeling with Apache Cassandra"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query 1 : Return the artist, song title and song's length in the music app history that was heard during a given sessionId and itemInSession\n",
    "\n",
    "In order to execute the Query above in Apache Cassandra, first we need to create a table modeled to this Query.\n",
    "\n",
    "For this, we will have as PRIMARY KEY the attribute `sessionId` as **Partition Key** and `itemInSession` as ours **Clustering Key**. The `sessionId` will be **hashed** to be divided among the Nodes and the query will use `itemInSession` to sort the `sessionId` in **Ascending** order."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the Table `artist_library`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Creating the table artist_library for the First Query\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_library \"\n",
    "\n",
    "query += \"(session_id int, item_in_session int, artist_name varchar, song_title text, \\\n",
    "    song_length decimal, PRIMARY KEY((session_id), item_in_session))\"\n",
    "\n",
    "try:\n",
    "    # Creating the table for query 01\n",
    "    session.execute(query)\n",
    "    print('Table artist_library created with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)                 "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table artist_library created with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inserting data into the Table `artist_library`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "# Opening event_datafile_new.csv\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "\n",
    "    # Loop to pass in each line of the csv file\n",
    "    for line in csvreader:\n",
    "        # Assigning the INSERT statement into the `query` variable\n",
    "        query = \"\"\"\n",
    "            INSERT INTO artist_library \n",
    "                (\n",
    "                    session_id, \n",
    "                    item_in_session, \n",
    "                    artist_name, \n",
    "                    song_title, \n",
    "                    song_length\n",
    "                )\n",
    "        \"\"\"\n",
    "        query += \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        # Assigning the right values for each column.\n",
    "        try:\n",
    "            # Inserting values on table artist_library\n",
    "            session.execute(\n",
    "                query, \n",
    "                (\n",
    "                    int(line[8]), \n",
    "                    int(line[3]), \n",
    "                    line[0], \n",
    "                    line[9], \n",
    "                    float(line[5])\n",
    "                )\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Printing EXCEPTION in case of error\n",
    "            print(e)\n",
    "\n",
    "print('Values inserted on table artist_library.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Values inserted on table artist_library.\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running the Query 01"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Query 01\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    artist_name, \n",
    "    song_title, \n",
    "    song_length \n",
    "FROM \n",
    "    artist_library \n",
    "WHERE \n",
    "    session_id = 338 \n",
    "        AND \n",
    "    item_in_session  = 4 \n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Executing the Query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)\n",
    "\n",
    "print('The return for Query 01 is:\\n')\n",
    "for row in rows:\n",
    "    # Printing the return of the Query 01\n",
    "    print(row.artist_name, row.song_title, row.song_length)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The return for Query 01 is:\n",
      "\n",
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query 02 : Return only the following requirements: name of artist, song (sorted by itemInSession) and user (first and last name) for a specific userid and sessionid\n",
    "\n",
    "In order to execute the Query above in Apache Cassandra, it is necessary to create a table modeled specifically to this Query.\n",
    "\n",
    "For this, we will have as PRIMARY KEY the attributes ((`userId`, `sessionId`), `itemInSession`). The **Partition Key** will be represented by (`userId`, `sessionId`) because if we choose to use only `userId` as **Partition Key** it is very likely that there will not have a fairl distribution across the node since there are some repeated `userId`. \n",
    "\n",
    "That is the reason why we should use both (`userId`, `sessionId`) as **Partition Key** to avoid having a concentration of data in one node for instance.\n",
    "\n",
    "The `itemInSession` will be used as our **Clustering Key**. The `userId` and `sessionId` will be **hashed** to be divided among the Nodes and the query will use `itemInSession` to sort the data a in **Ascending** order."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Table `user_library`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS user_library \"\n",
    "\n",
    "query += \"(user_id int, session_id int, item_in_session int, first_name varchar, last_name varchar, \\\n",
    "    artist_name varchar, song_title text, PRIMARY KEY((user_id, session_id), item_in_session))\"\n",
    "\n",
    "try:\n",
    "    # Creating table user_library\n",
    "    session.execute(query)\n",
    "    print('Table user_library created with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table user_library created with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inserting data into Table `user_library`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Opening event_datafile_new.csv\n",
    "with open(file, encoding = 'utf-8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "\n",
    "    for line in csvreader:\n",
    "        # Assigning the INSERT statement into the `query` variable\n",
    "        query = \"\"\"\n",
    "            INSERT INTO user_library\n",
    "                (\n",
    "                    user_id,\n",
    "                    session_id,\n",
    "                    item_in_session,\n",
    "                    first_name,\n",
    "                    last_name,\n",
    "                    artist_name,\n",
    "                    song_title\n",
    "                )\n",
    "        \"\"\" \n",
    "\n",
    "        query += \" VALUES (%s, %s, %s, %s, %s, %s, %s)\" \n",
    "\n",
    "        # Assigning the right values for each column on table user_library\n",
    "        try:\n",
    "            # Inserting values on table user_library\n",
    "            session.execute(\n",
    "                query,\n",
    "                (\n",
    "                    int(line[10]),\n",
    "                    int(line[8]),\n",
    "                    int(line[3]),\n",
    "                    line[1],\n",
    "                    line[4],\n",
    "                    line[0],\n",
    "                    line[9]\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Printing EXCEPTION in case of error\n",
    "            print(e)\n",
    "print('Values inserted on table user_library.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Values inserted on table user_library.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Query 02"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Query 02\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    artist_name,\n",
    "    song_title,\n",
    "    first_name,\n",
    "    last_name\n",
    "FROM \n",
    "    user_library\n",
    "WHERE\n",
    "    user_id = 10\n",
    "        AND\n",
    "    session_id = 182\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Executing the query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)\n",
    "\n",
    "print('The return for Query 02 is:\\n')\n",
    "for row in rows:\n",
    "    print(row.artist_name, row.song_title, row.first_name, row.last_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The return for Query 02 is:\n",
      "\n",
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query 03 : Return every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "In order to execute the Query above in Apache Cassandra, it is necessary to create a table modeled specifically to this Query.\n",
    "\n",
    "For this reason, we will have as PRIMARY KEY the attributes ((`song`), `userId`). The **Partition Key** will be represented by `song` since it is what we want to query and our **Clustering Key** will be represented by `userId` which will hash our **Partition Key**, give the uniquiness to the PRIMARY KEY, and sort the data a in a **Ascending** order."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Table `user_history`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS users_history \"\n",
    "\n",
    "query += \"(song_title text, user_id int, first_name varchar, last_name varchar, \\\n",
    "    PRIMARY KEY(song_title, user_id))\"\n",
    "\n",
    "try:\n",
    "    # Creating table user_history\n",
    "    session.execute(query)\n",
    "    print('Table users_history created with success.')\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table users_history created with success.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inserting data into Table `user_history`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open(file, encoding = 'utf-8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "\n",
    "    for line in csvreader:\n",
    "    ## Assigning the INSERT statement into the `query` variable\n",
    "        query = \"\"\"\n",
    "            INSERT INTO users_history\n",
    "                (\n",
    "                    song_title,\n",
    "                    user_id,\n",
    "                    first_name,\n",
    "                    last_name     \n",
    "                )\n",
    "        \"\"\" \n",
    "\n",
    "        query += \" VALUES (%s, %s, %s, %s)\" \n",
    "\n",
    "        # Assigning the right values for each column on table users_history\n",
    "        try:\n",
    "            # Inserting values on table user_library\n",
    "            session.execute(\n",
    "                query,\n",
    "                (\n",
    "                    line[9],\n",
    "                    int(line[10]),\n",
    "                    line[1],\n",
    "                    line[4]\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Printing EXCEPTION in case of error\n",
    "            print(e)\n",
    "print('Values inserted on table users_history.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Values inserted on table users_history.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Query 03"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    first_name,\n",
    "    last_name\n",
    "FROM\n",
    "    users_history\n",
    "WHERE\n",
    "    song_title = 'All Hands Against His Own'\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Executing the query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    # Printing EXCEPTION in case of error\n",
    "    print(e)\n",
    "\n",
    "print('The return for Query 03 is:\\n')\n",
    "for row in rows:\n",
    "    print(row.first_name, row.last_name)                  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The return for Query 03 is:\n",
      "\n",
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop the tables before closing out the sessions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Dropping the tables \n",
    "table_list = ['artist_library', 'user_library', 'users_history']\n",
    "\n",
    "for table in table_list:\n",
    "    query = \"DROP TABLE {}\".format(table)\n",
    "    try:\n",
    "        # Executing the query\n",
    "        session.execute(query)\n",
    "        print('Table {} dropped.\\n'.format(table))\n",
    "    except Exception as e:\n",
    "        # Printing EXCEPTION in case of error\n",
    "        print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table artist_library dropped.\n",
      "\n",
      "Table user_library dropped.\n",
      "\n",
      "Table users_history dropped.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Close the session and cluster connection¶"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('nanodegree-venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "0aa14502d21e2a26bfc18e55e2d280a7e63eaf5ceb3c87cd933351da57148454"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}